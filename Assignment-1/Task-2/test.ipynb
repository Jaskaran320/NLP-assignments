{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deeptanshu Barman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from bigram import BigramLM\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utils import emotion_scores\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_path = '../data/corpus.txt'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(corpus_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Add a \"$\" sign to the beginning of each line\n",
    "modified_lines = ['$ ' + line.strip() for line in lines]\n",
    "joined_string = '\\n'.join(modified_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=joined_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Initialized ðŸŸ¢\n",
      "Tokens Set ðŸŸ¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating Bigram Matrix...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48931/48931 [00:00<00:00, 493398.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Matrices Calculated ðŸŸ¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Kneser-Ney Matrix...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5430/5430 [00:57<00:00, 94.11it/s] \n"
     ]
    }
   ],
   "source": [
    "model = BigramLM(corpus)\n",
    "model.set_token()\n",
    "model.calculate_bigrams()\n",
    "laplace_matrix = model.get_laplace_matrix()\n",
    "kn_matrix = model.set_kn_matrix(d=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Emotion for all non-zero Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.get_token()\n",
    "count_matrix = model.get_count_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aahhh',\n",
       " 'abandoning',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'able',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'abused',\n",
       " 'abuses',\n",
       " 'abusive',\n",
       " 'abyss',\n",
       " 'academic',\n",
       " 'academics',\n",
       " 'accelerated',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accessaries',\n",
       " 'accessibility',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accomplished',\n",
       " 'accomplishing',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'ache',\n",
       " 'ached',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achieving',\n",
       " 'aching',\n",
       " 'acne',\n",
       " 'acquainted',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adjust',\n",
       " 'administration',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admiring',\n",
       " 'admit',\n",
       " 'admitting',\n",
       " 'adn',\n",
       " 'adolescence',\n",
       " 'adomen',\n",
       " 'adopt',\n",
       " 'adore',\n",
       " 'adoring',\n",
       " 'adrasteius',\n",
       " 'adulthood',\n",
       " 'advance',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'advice',\n",
       " 'advocate',\n",
       " 'aesthetics',\n",
       " 'afaerytaleinmakebelieve',\n",
       " 'affectionate',\n",
       " 'affects',\n",
       " 'affirmation',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aggressive',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aim',\n",
       " 'aimless',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alaska',\n",
       " 'albeit',\n",
       " 'alcohol',\n",
       " 'alene',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexander',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'aligncenter',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allen',\n",
       " 'allies',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowfullscreen',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazingness',\n",
       " 'ambient',\n",
       " 'ambition',\n",
       " 'ambulance',\n",
       " 'ambulatory',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americas',\n",
       " 'amish',\n",
       " 'among',\n",
       " 'amorous',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amplified',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'an',\n",
       " 'analyses',\n",
       " 'ancestral',\n",
       " 'and',\n",
       " 'andare',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angered',\n",
       " 'angry',\n",
       " 'anguished',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'anime',\n",
       " 'ankle',\n",
       " 'anna',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anthology',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'antics',\n",
       " 'antique',\n",
       " 'antisocial',\n",
       " 'ants',\n",
       " 'anxieties',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'aoi',\n",
       " 'aout',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apathetic',\n",
       " 'apathy',\n",
       " 'apocalypses',\n",
       " 'apologise',\n",
       " 'apologizes',\n",
       " 'apology',\n",
       " 'appalled',\n",
       " 'appealing',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appetite',\n",
       " 'apples',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehensive',\n",
       " 'appriciation',\n",
       " 'approach',\n",
       " 'appropriately',\n",
       " 'approve',\n",
       " 'appts',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'arcade',\n",
       " 'architectural',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'arent',\n",
       " 'argued',\n",
       " 'argument',\n",
       " 'arm',\n",
       " 'armor',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'around',\n",
       " 'aroused',\n",
       " 'arrangment',\n",
       " 'arrived',\n",
       " 'arrogance',\n",
       " 'art',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articulate',\n",
       " 'artisan',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artists',\n",
       " 'artwork',\n",
       " 'arun',\n",
       " 'aryiku',\n",
       " 'as',\n",
       " 'ashamed',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'ass',\n",
       " 'assaulted',\n",
       " 'assessment',\n",
       " 'asset',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'association',\n",
       " 'assuage',\n",
       " 'assume',\n",
       " 'assured',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'athletics',\n",
       " 'ativan',\n",
       " 'atleast',\n",
       " 'atmosphere',\n",
       " 'atop',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacking',\n",
       " 'attainable',\n",
       " 'attempt',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attire',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attractive',\n",
       " 'audience',\n",
       " 'aunt',\n",
       " 'austen',\n",
       " 'auster',\n",
       " 'australia',\n",
       " 'australians',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'authors',\n",
       " 'automation',\n",
       " 'available',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'aversion',\n",
       " 'avoid',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awoke',\n",
       " 'awoken',\n",
       " 'axilla',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'baachan',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'babysit',\n",
       " 'back',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backlogs',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'baffled',\n",
       " 'baffroom',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'bags',\n",
       " 'baking',\n",
       " 'bal',\n",
       " 'balance',\n",
       " 'balancing',\n",
       " 'balks',\n",
       " 'ball',\n",
       " 'ballistic',\n",
       " 'balloons',\n",
       " 'baltic',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'banishes',\n",
       " 'bank',\n",
       " 'banter',\n",
       " 'baptized',\n",
       " 'barefoot',\n",
       " 'barely',\n",
       " 'barrage',\n",
       " 'barrier',\n",
       " 'bars',\n",
       " 'based',\n",
       " 'bashful',\n",
       " 'basically',\n",
       " 'basks',\n",
       " 'bastard',\n",
       " 'batch',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battered',\n",
       " 'battle',\n",
       " 'bayou',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'bears',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beatles',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'bedrooms',\n",
       " 'bedside',\n",
       " 'bee',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'befriending',\n",
       " 'befuddled',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'begleiter',\n",
       " 'behavior',\n",
       " 'behaviors',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'being',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believer',\n",
       " 'believing',\n",
       " 'belittle',\n",
       " 'belittled',\n",
       " 'bellingham',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'beloved',\n",
       " 'below',\n",
       " 'ben',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'bengals',\n",
       " 'benjamin',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'betrayed',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beware',\n",
       " 'beyonc',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bi',\n",
       " 'biannual',\n",
       " 'bias',\n",
       " 'bible',\n",
       " 'bicycle',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggie',\n",
       " 'bike',\n",
       " 'billy',\n",
       " 'binge',\n",
       " 'bio',\n",
       " 'biochemistry',\n",
       " 'bird',\n",
       " 'birding',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'birthdays',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitchy',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'bitterly',\n",
       " 'bittersweet',\n",
       " 'blabber',\n",
       " 'black',\n",
       " 'blah',\n",
       " 'blair',\n",
       " 'blaming',\n",
       " 'blank',\n",
       " 'blanked',\n",
       " 'blanket',\n",
       " 'blankets',\n",
       " 'blend',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blind',\n",
       " 'blinded',\n",
       " 'blinds',\n",
       " 'blink',\n",
       " 'bliss',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blog',\n",
       " 'bloggers',\n",
       " 'blogging',\n",
       " 'blogs',\n",
       " 'blogspot',\n",
       " 'bloke',\n",
       " 'blonde',\n",
       " 'bloom',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blue',\n",
       " 'blush',\n",
       " 'board',\n",
       " 'boards',\n",
       " 'boat',\n",
       " 'body',\n",
       " 'bodys',\n",
       " 'bold',\n",
       " 'bondmusings',\n",
       " 'bones',\n",
       " 'bonka',\n",
       " 'bonus',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'bookmark',\n",
       " 'books',\n",
       " 'boost',\n",
       " 'booth',\n",
       " 'boots',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'borne',\n",
       " 'boss',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothersome',\n",
       " 'bought',\n",
       " 'bounces',\n",
       " 'bouncy',\n",
       " 'boundaries',\n",
       " 'bout',\n",
       " 'bowled',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boyfriends',\n",
       " 'boys',\n",
       " 'bqff',\n",
       " 'brag',\n",
       " 'brain',\n",
       " 'brains',\n",
       " 'brand',\n",
       " 'branding',\n",
       " 'brandish',\n",
       " 'brave',\n",
       " 'brd',\n",
       " 'brds',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breakup',\n",
       " 'breast',\n",
       " 'breastfeeding',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathing',\n",
       " 'breaths',\n",
       " 'breeds',\n",
       " 'breeze',\n",
       " 'brew',\n",
       " 'bridal',\n",
       " 'bride',\n",
       " 'bridezillas',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brimming',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brooks',\n",
       " 'broom',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brownish',\n",
       " 'browsers',\n",
       " 'brush',\n",
       " 'bsc',\n",
       " 'bu',\n",
       " 'buffed',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'bundle',\n",
       " 'bungalow',\n",
       " 'bunion',\n",
       " 'buoyed',\n",
       " 'burdened',\n",
       " 'burgeoning',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burnt',\n",
       " 'burrowing',\n",
       " 'burst',\n",
       " 'bury',\n",
       " 'burying',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'busting',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butt',\n",
       " 'butterflies',\n",
       " 'butterfly',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buys',\n",
       " 'buzzy',\n",
       " 'by',\n",
       " 'c',\n",
       " 'cabin',\n",
       " 'california',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'callous',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'calming',\n",
       " 'calorie',\n",
       " 'cambodia',\n",
       " 'came',\n",
       " 'campaign',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'cancer',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cantankerous',\n",
       " 'canvas',\n",
       " 'capable',\n",
       " 'capital',\n",
       " 'capp',\n",
       " 'caps',\n",
       " 'capture',\n",
       " 'car',\n",
       " 'cara',\n",
       " 'carcass',\n",
       " 'carcenogenic',\n",
       " 'card',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'cared',\n",
       " 'career',\n",
       " 'careers',\n",
       " 'careess',\n",
       " 'carefree',\n",
       " 'careful',\n",
       " 'carelessness',\n",
       " 'cares',\n",
       " 'carin',\n",
       " 'caring',\n",
       " 'carried',\n",
       " 'carrry',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'cars',\n",
       " 'cartwheel',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'casting',\n",
       " 'castle',\n",
       " 'casual',\n",
       " 'casually',\n",
       " 'catalyst',\n",
       " 'catapulted',\n",
       " 'catch',\n",
       " 'category',\n",
       " 'catholic',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causes',\n",
       " 'causing',\n",
       " 'cautious',\n",
       " 'cave',\n",
       " 'cawing',\n",
       " 'celebrate',\n",
       " 'celebrates',\n",
       " 'celebrating',\n",
       " 'celebrations',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'centered',\n",
       " 'century',\n",
       " 'cert',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'certified',\n",
       " 'chabad',\n",
       " 'chained',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'challenged',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'chambers',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'chaos',\n",
       " 'chapter',\n",
       " 'chapters',\n",
       " 'character',\n",
       " 'characterisation',\n",
       " 'characters',\n",
       " 'charged',\n",
       " 'charging',\n",
       " 'charity',\n",
       " 'charmed',\n",
       " 'charred',\n",
       " 'chat',\n",
       " 'chatter',\n",
       " 'chatting',\n",
       " 'cheap',\n",
       " 'cheated',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'cheering',\n",
       " 'cheerleader',\n",
       " 'cheese',\n",
       " 'cheesecake',\n",
       " 'chemistry',\n",
       " 'cherish',\n",
       " 'chest',\n",
       " 'chiangmai',\n",
       " 'chick',\n",
       " 'chiharu',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'chills',\n",
       " 'china',\n",
       " 'chinas',\n",
       " 'chins',\n",
       " 'chocolate',\n",
       " 'chocolating',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choke',\n",
       " 'choose',\n",
       " 'chore',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christchurch',\n",
       " 'christian',\n",
       " 'christians',\n",
       " 'christmas',\n",
       " 'christmassy',\n",
       " 'chronically',\n",
       " 'chuffed',\n",
       " 'church',\n",
       " 'cigarette',\n",
       " 'cigarettes',\n",
       " 'cinnamon',\n",
       " 'circle',\n",
       " 'circles',\n",
       " 'circumstance',\n",
       " 'cited',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'clammy',\n",
       " 'clamouring',\n",
       " 'clara',\n",
       " 'clarify',\n",
       " 'clash',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'classy',\n",
       " 'clay',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clearing',\n",
       " 'clearly',\n",
       " 'clench',\n",
       " 'clenches',\n",
       " 'clever',\n",
       " 'cliched',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'clinique',\n",
       " 'clock',\n",
       " 'cloest',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closet',\n",
       " 'closing',\n",
       " 'closure',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'clouds',\n",
       " 'clover',\n",
       " 'club',\n",
       " 'clubbed',\n",
       " 'clubbing',\n",
       " 'clubs',\n",
       " 'clue',\n",
       " 'clues',\n",
       " 'clung',\n",
       " 'clutter',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'cobwebs',\n",
       " 'cocktail',\n",
       " 'code',\n",
       " 'coerce',\n",
       " 'coeur',\n",
       " 'coffee',\n",
       " 'cognitive',\n",
       " 'cohen',\n",
       " 'cold',\n",
       " 'collected',\n",
       " 'collection',\n",
       " 'collective',\n",
       " 'college',\n",
       " 'color',\n",
       " 'colors',\n",
       " 'coloured',\n",
       " 'colours',\n",
       " 'column',\n",
       " 'com',\n",
       " 'comatose',\n",
       " 'combined',\n",
       " 'combo',\n",
       " 'come',\n",
       " 'comeback',\n",
       " 'comedies',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comforted',\n",
       " 'comforting',\n",
       " 'comfy',\n",
       " 'coming',\n",
       " 'comings',\n",
       " 'commands',\n",
       " 'comment',\n",
       " 'commented',\n",
       " 'comments',\n",
       " 'commit',\n",
       " 'committee',\n",
       " 'committing',\n",
       " 'common',\n",
       " 'communal',\n",
       " 'communicated',\n",
       " 'communicates',\n",
       " 'communication',\n",
       " 'communing',\n",
       " 'community',\n",
       " 'companies',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'compassion',\n",
       " 'compassionate',\n",
       " 'compensated',\n",
       " 'complacent',\n",
       " 'complaining',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'completeness',\n",
       " 'completing',\n",
       " 'complications',\n",
       " 'comprehend',\n",
       " 'computer',\n",
       " 'computers',\n",
       " 'concentrate',\n",
       " 'concept',\n",
       " 'concerned',\n",
       " 'concerning',\n",
       " 'concerns',\n",
       " 'concieve',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'concoction',\n",
       " 'condemn',\n",
       " 'condemned',\n",
       " 'condemning',\n",
       " 'condition',\n",
       " 'conditions',\n",
       " 'conducive',\n",
       " 'conducting',\n",
       " 'confess',\n",
       " 'confessions',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confined',\n",
       " 'confirm',\n",
       " 'confrontation',\n",
       " 'confused',\n",
       " 'confusion',\n",
       " 'congress',\n",
       " 'connect',\n",
       " 'connecting',\n",
       " 'connection',\n",
       " 'connections',\n",
       " 'conor',\n",
       " 'conscience',\n",
       " 'conscious',\n",
       " 'consciously',\n",
       " 'consequences',\n",
       " 'consequently',\n",
       " 'conservatives',\n",
       " 'considerate',\n",
       " 'considering',\n",
       " 'consignment',\n",
       " 'consistently',\n",
       " 'console',\n",
       " 'consolidation',\n",
       " 'conspiracy',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'constructions',\n",
       " 'constructive',\n",
       " 'constructively',\n",
       " 'constructivism',\n",
       " 'consumer',\n",
       " 'consumers',\n",
       " 'consuming',\n",
       " 'contact',\n",
       " 'contagious',\n",
       " 'contain',\n",
       " 'contemplating',\n",
       " 'contemplation',\n",
       " 'content',\n",
       " 'contented',\n",
       " 'contentedly',\n",
       " 'context',\n",
       " 'continually',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'continuing',\n",
       " 'continuous',\n",
       " 'continuously',\n",
       " 'contract',\n",
       " 'contractions',\n",
       " 'contracts',\n",
       " 'contrary',\n",
       " 'contribute',\n",
       " 'control',\n",
       " 'convenience',\n",
       " 'convention',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'conversing',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'convoluted',\n",
       " 'cook',\n",
       " 'cookie',\n",
       " 'cool',\n",
       " 'cooped',\n",
       " 'cooperation',\n",
       " 'coordinate',\n",
       " 'cop',\n",
       " 'cope',\n",
       " 'copies',\n",
       " 'coppers',\n",
       " 'copping',\n",
       " 'copyright',\n",
       " ...]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5430it [12:24,  7.29it/s]\n"
     ]
    }
   ],
   "source": [
    "emotions = {}\n",
    "for i, token in tqdm(enumerate(tokens)):\n",
    "    for j, token2 in enumerate(tokens):\n",
    "        if count_matrix[i][j] > 0 and token!='$' and token2!=\"$\":\n",
    "            emotions[(token, token2)] = emotion_scores(str(token + \" \" + token2))\n",
    "        if count_matrix[i][j] > 0 and token=='$' and token2!=\"$\":\n",
    "            emotions[(token, token2)]= emotion_scores(str(token2))\n",
    "        if count_matrix[i][j] > 0 and token!='$' and token2==\"$\":\n",
    "            emotions[(token, token2)]= emotion_scores(str(token))\n",
    "\n",
    "with open('emotions.pkl', 'wb') as f:\n",
    "    pickle.dump(emotions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo = pickle.load(open(\"pickle_files/emotions.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 50 Sentences each of every emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sadness Matix: 5430it [00:19, 280.76it/s]\n",
      "Generating Sentence: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:02<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Generated + Stored ðŸŸ¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating joy Matix: 5430it [00:20, 261.55it/s]\n",
      "Generating Sentence: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:02<00:00, 23.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Generated + Stored ðŸŸ¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating love Matix: 5430it [00:19, 277.66it/s]\n",
      "Generating Sentence: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:02<00:00, 22.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Generated + Stored ðŸŸ¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating anger Matix: 5430it [00:18, 291.95it/s]\n",
      "Generating Sentence: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:02<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Generated + Stored ðŸŸ¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fear Matix: 5430it [00:20, 269.13it/s]\n",
      "Generating Sentence: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:01<00:00, 25.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Generated + Stored ðŸŸ¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating surprise Matix: 5430it [00:20, 260.45it/s]\n",
      "Generating Sentence: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:02<00:00, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences Generated + Stored ðŸŸ¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emotions=[\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "for i in emotions:\n",
    "    # used count matrix use some other matrix like laplace or kneser-ney\n",
    "    model.generate_sentences(model.get_kn_matrix(), emotion=i, word_limit=15, no_of_sentences=50, alpha = 1, beta = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"..\\data\\corpus.txt\"\n",
    "labels_file = \"..\\data\\labels.txt\"\n",
    "with open(corpus_file) as f:\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(f)\n",
    "    fts = vectorizer.get_feature_names_out()\n",
    "# print(X)\n",
    "\n",
    "with open(labels_file) as l:\n",
    "    y = l.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel': ('linear', 'rbf'), 'C': [1, 3, 5], 'gamma': [0.1, 0.05, 0.01], \"degree\": [2, 3, 5], 'tol': [0.001, 0.0001]}\n",
    "clf = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale')\n",
    "# clf = GridSearchCV(svc, parameters, n_jobs=4)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.best_params_)\n",
    "# print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966666666666667\n"
     ]
    }
   ],
   "source": [
    "clf.predict(X)\n",
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=[\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "dataset = {}\n",
    "for emotion in emotions:\n",
    "    path = \".\\emotion_text\\gen_\"+emotion+\".txt\"\n",
    "    with open(path, 'r') as file:\n",
    "        dataset[emotion] = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness 0.74\n",
      "joy 0.68\n",
      "love 0.96\n",
      "anger 0.42\n",
      "fear 0.58\n",
      "surprise 0.84\n",
      "Average accuracy:  0.7033333333333333\n"
     ]
    }
   ],
   "source": [
    "def emotion_accuracy(emotion, dataset, clf):\n",
    "    X = vectorizer.transform(dataset[emotion])\n",
    "    y = [emotion]*len(dataset[emotion])\n",
    "    return clf.score(X, y)\n",
    "\n",
    "for emotion in emotions:\n",
    "    print(emotion, emotion_accuracy(emotion, dataset, clf)) \n",
    "   \n",
    "print(\"Average accuracy: \", np.mean([emotion_accuracy(emotion, dataset, clf) for emotion in emotions]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
