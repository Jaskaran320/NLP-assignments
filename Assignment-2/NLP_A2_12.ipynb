{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGFBhw_ByE3Y"
      },
      "source": [
        "# Imports and Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o0Iz9Yft-YK5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1PcKYeSxnUR",
        "outputId": "805441e6-4320-404b-b76e-0ee6d2dbdca3"
      },
      "outputs": [],
      "source": [
        "request_NER_TRAIN = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/NER_TRAIN_JUDGEMENT.json\")\n",
        "request_NER_TEST = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/NER_TEST_JUDGEMENT.json\")\n",
        "request_LR_VAL = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/Laptop_Review_Val.json\")\n",
        "request_LR_TEST = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/Laptop_Review_Test.json\")\n",
        "request_LR_TRAIN = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/Laptop_Review_Train.json\")\n",
        "\n",
        "\n",
        "import os\n",
        "if not os.path.exists(\"./data\"):\n",
        "    os.makedirs(\"./data\")\n",
        "\n",
        "with open(\"./data/NER_train.json\", \"x\") as file:\n",
        "    file.write(request_NER_TRAIN.text)\n",
        "\n",
        "with open(\"./data/NER_test.json\", \"x\") as file:\n",
        "    file.write(request_NER_TEST.text)\n",
        "    \n",
        "with open(\"./data/LR_Val.json\", \"x\") as file:\n",
        "    file.write(request_LR_VAL.text)\n",
        "    \n",
        "with open(\"./data/LR_test.json\", \"x\") as file:\n",
        "    file.write(request_LR_TEST.text)\n",
        "\n",
        "with open(\"./data/LR_Train.json\", \"x\") as file:\n",
        "    file.write(request_LR_TRAIN.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSSJ-Dan-eX0"
      },
      "outputs": [],
      "source": [
        "NER_train_file = open(\"./data/NER_train.json\")\n",
        "NER_train_json = json.load(NER_train_file)\n",
        "\n",
        "NER_test_file = open(\"./data/NER_test.json\")\n",
        "NER_test_json = json.load(NER_test_file)\n",
        "\n",
        "LR_train_file = open(\"./data/LR_Train.json\")\n",
        "LR_train_json = json.load(LR_train_file)\n",
        "\n",
        "LR_val_file = open(\"./data/LR_Train.json\")\n",
        "LR_val_json = json.load(LR_val_file)\n",
        "\n",
        "LR_test_file = open(\"./data/LR_Train.json\")\n",
        "LR_test_json = json.load(LR_test_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LR_Preprocessor:\n",
        "    def __init__(self,trainset,testset,valset):\n",
        "        self.trainset = trainset\n",
        "        self.testset = testset\n",
        "        self.valset = valset\n",
        "\n",
        "    def init_tags(self,dataset):\n",
        "        labeled_outputs = []\n",
        "        id = 0\n",
        "        for entry in dataset:\n",
        "            tag_entry = {}\n",
        "            tag_entry[\"id\"] = id \n",
        "            tag_entry[\"text\"] = entry[\"raw_words\"]\n",
        "            tag_entry[\"labels\"] = len(entry[\"words\"])*[\"O\"]\n",
        "            for aspect in entry[\"aspects\"]:\n",
        "                for index in range(aspect[\"from\"],aspect[\"to\"]):\n",
        "                    if index == aspect[\"from\"]:\n",
        "                        tag_entry[\"labels\"][index] = \"B\"\n",
        "                    else:\n",
        "                        tag_entry[\"labels\"][index] = \"I\"\n",
        "                        \n",
        "            labeled_outputs.append(tag_entry)   \n",
        "            id += 1\n",
        "        return labeled_outputs\n",
        "        \n",
        "    def initizalize(self):\n",
        "        self.labeled_trainset = self.init_tags(self.trainset)\n",
        "        self.labeled_valset = self.init_tags(self.valset)\n",
        "        self.labeled_testset = self.init_tags(self.testset)\n",
        "    \n",
        "    def get_tagged_data(self):\n",
        "        return self.labeled_trainset,self.labeled_valset,self.labeled_testset\n",
        "        \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkjnXksYHYZN"
      },
      "outputs": [],
      "source": [
        "class NER_Preprocessor:\n",
        "    def __init__(self, trainset, testset, valset=None):\n",
        "        self.trainset = trainset\n",
        "        self.testset = testset\n",
        "        self.valset = valset\n",
        "        if valset is None:\n",
        "            self.split_val()\n",
        "    \n",
        "    def split_val(self, split_train_false=False):\n",
        "        if split_train_false:\n",
        "            self.trainset = self.trainset + self.valset\n",
        "        self.trainset, self.valset = train_test_split(\n",
        "            self.trainset, test_size=0.15, random_state=42)\n",
        "\n",
        "    def init_tags(self, dataset):\n",
        "        labeled_output = []\n",
        "        for entry in dataset:\n",
        "            tag_entry = {}\n",
        "            tag_entry[\"id\"] = entry[\"id\"]\n",
        "            tag_entry[\"text\"] = entry[\"data\"][\"text\"]\n",
        "            annotations = entry[\"annotations\"][0]\n",
        "            data = entry[\"data\"]\n",
        "            meta = entry[\"meta\"]\n",
        "            tag_entry[\"labels\"] = []\n",
        "            char_itr = 0\n",
        "            for result_obj in annotations[\"result\"]:\n",
        "                if char_itr > result_obj[\"value\"][\"start\"]:\n",
        "                    continue\n",
        "                tagged_words = result_obj[\"value\"][\"text\"].split(\" \")\n",
        "                num_words = len(tagged_words)\n",
        "                tags = \"B_\" + result_obj[\"value\"][\"labels\"][0] + \\\n",
        "                    (\" I_\"+result_obj[\"value\"][\"labels\"][0]) * (num_words-1)\n",
        "                while (char_itr < result_obj[\"value\"][\"start\"]):\n",
        "                    if (entry[\"data\"][\"text\"][char_itr] == \" \"):\n",
        "                        tag_entry[\"labels\"].append(\"O\")\n",
        "                    char_itr += 1\n",
        "\n",
        "                for tag in tags.split(\" \"):\n",
        "                    tag_entry[\"labels\"].append(tag)\n",
        "\n",
        "                char_itr = result_obj[\"value\"][\"end\"]\n",
        "                while (char_itr < len(entry[\"data\"][\"text\"]) and entry[\"data\"][\"text\"][char_itr] != \" \"):\n",
        "                    char_itr += 1\n",
        "                char_itr += 1\n",
        "\n",
        "            while (char_itr < len(entry[\"data\"][\"text\"])):\n",
        "                if (entry[\"data\"][\"text\"][char_itr] == \" \"):\n",
        "                    tag_entry[\"labels\"].append(\"O\")\n",
        "                char_itr += 1\n",
        "\n",
        "            if char_itr == len(entry[\"data\"][\"text\"]):\n",
        "                tag_entry[\"labels\"].append(\"O\")\n",
        "            \n",
        "            labeled_output.append(tag_entry)\n",
        "        \n",
        "        return labeled_output\n",
        "      \n",
        "    def initialize(self):\n",
        "        self.labeled_trainset = self.init_tags(self.trainset)\n",
        "        self.labeled_valset  = self.init_tags(self.valset)\n",
        "        self.labeled_testset = self.init_tags(self.testset)\n",
        "\n",
        "    def get_tagged(self):\n",
        "        return (self.labeled_trainset, self.labeled_valset, self.labeled_testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NER_preprocessor = NER_Preprocessor(NER_train_json, NER_test_json)\n",
        "NER_preprocessor.initialize()\n",
        "NER_train,NER_val,NER_test = NER_preprocessor.get_tagged()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (not os.path.exists(\"./processed\")):\n",
        "    os.makedirs(\"./processed\")\n",
        "\n",
        "with open(\"./processed/NER_train_tagged.json\", \"w\") as file:\n",
        "    json.dump(NER_train, file)\n",
        "    \n",
        "with open(\"./processed/NER_val_tagged.json\", \"w\") as file:\n",
        "    json.dump(NER_val, file)\n",
        "\n",
        "with open(\"./processed/NER_test_tagged.json\", \"w\") as file:\n",
        "    json.dump(NER_test, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LR_Preprocessor = LR_Preprocessor(LR_train_json,LR_test_json,LR_val_json)\n",
        "LR_Preprocessor.initizalize()\n",
        "LR_train,LR_val,LR_test = LR_Preprocessor.get_tagged_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./processed/LR_train_tagged.json\", \"w\") as file:\n",
        "    json.dump(LR_train, file)\n",
        "\n",
        "with open(\"./processed/LR_val_tagged.json\", \"w\") as file:\n",
        "    json.dump(LR_val, file)\n",
        "    \n",
        "with open(\"./processed/LR_test_tagged.json\", \"w\") as file:\n",
        "    json.dump(LR_test, file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
