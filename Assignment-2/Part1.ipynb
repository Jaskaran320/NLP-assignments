{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGFBhw_ByE3Y"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o0Iz9Yft-YK5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1PcKYeSxnUR",
        "outputId": "805441e6-4320-404b-b76e-0ee6d2dbdca3"
      },
      "outputs": [],
      "source": [
        "# request_NER_TRAIN = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/NER_TRAIN_JUDGEMENT.json\")\n",
        "# request_NER_TEST = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/NER_TEST_JUDGEMENT.json\")\n",
        "# request_LR_VAL = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/Laptop_Review_Val.json\")\n",
        "# request_LR_TEST = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/Laptop_Review_Test.json\")\n",
        "# request_LR_TRAIN = requests.get(\"http://AdityaAhuja01.pythonanywhere.com/data/NLP_Data/Laptop_Review_Train.json\")\n",
        "\n",
        "# if not os.path.exists(\"./data\"):\n",
        "#     os.makedirs(\"./data\")\n",
        "\n",
        "# with open(\"./data/NER_train.json\", \"x\") as file:\n",
        "#     file.write(request_NER_TRAIN.text)\n",
        "\n",
        "# with open(\"./data/NER_test.json\", \"x\") as file:\n",
        "#     file.write(request_NER_TEST.text)\n",
        "    \n",
        "# with open(\"./data/LR_Val.json\", \"x\") as file:\n",
        "#     file.write(request_LR_VAL.text)\n",
        "    \n",
        "# with open(\"./data/LR_test.json\", \"x\") as file:\n",
        "#     file.write(request_LR_TEST.text)\n",
        "\n",
        "# with open(\"./data/LR_Train.json\", \"x\") as file:\n",
        "#     file.write(request_LR_TRAIN.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xSSJ-Dan-eX0"
      },
      "outputs": [],
      "source": [
        "NER_train_file = open(\"./data/NER_train.json\")\n",
        "NER_train_json = json.load(NER_train_file)\n",
        "\n",
        "NER_test_file = open(\"./data/NER_test.json\")\n",
        "NER_test_json = json.load(NER_test_file)\n",
        "\n",
        "LR_train_file = open(\"./data/LR_Train.json\")\n",
        "LR_train_json = json.load(LR_train_file)\n",
        "\n",
        "LR_val_file = open(\"./data/LR_Val.json\")\n",
        "LR_val_json = json.load(LR_val_file)\n",
        "\n",
        "LR_test_file = open(\"./data/LR_Test.json\")\n",
        "LR_test_json = json.load(LR_test_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LR_Preprocessor:\n",
        "    def __init__(self,trainset,testset,valset):\n",
        "        self.trainset = trainset\n",
        "        self.testset = testset\n",
        "        self.valset = valset\n",
        "\n",
        "    def init_tags(self,dataset):\n",
        "        labeled_outputs = []\n",
        "        id = 0\n",
        "        for entry in dataset:\n",
        "            tag_entry = {}\n",
        "            tag_entry[\"id\"] = id \n",
        "            tag_entry[\"text\"] = entry[\"raw_words\"]\n",
        "            tag_entry[\"labels\"] = len(entry[\"words\"])*[\"O\"]\n",
        "            for aspect in entry[\"aspects\"]:\n",
        "                for index in range(aspect[\"from\"],aspect[\"to\"]):\n",
        "                    if index == aspect[\"from\"]:\n",
        "                        tag_entry[\"labels\"][index] = \"B\"\n",
        "                    else:\n",
        "                        tag_entry[\"labels\"][index] = \"I\"\n",
        "                        \n",
        "            labeled_outputs.append(tag_entry)   \n",
        "            id += 1\n",
        "        return labeled_outputs\n",
        "        \n",
        "    def initizalize(self):\n",
        "        self.labeled_trainset = self.init_tags(self.trainset)\n",
        "        self.labeled_valset = self.init_tags(self.valset)\n",
        "        self.labeled_testset = self.init_tags(self.testset)\n",
        "    \n",
        "    def get_tagged_data(self):\n",
        "        return self.labeled_trainset,self.labeled_valset,self.labeled_testset\n",
        "        \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_word_indices(test_str):\n",
        "    word_indices = []\n",
        "    start_index = 0\n",
        "    for i in range(len(test_str)):\n",
        "\n",
        "        if test_str[i] == \" \":\n",
        "            if start_index != i:\n",
        "                word_indices.append((start_index, i - 1))\n",
        "            start_index = i + 1\n",
        "\n",
        "    if start_index != len(test_str):\n",
        "        word_indices.append((start_index, len(test_str) - 1))\n",
        "    return word_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_alphanumeric_in_word(word):\n",
        "    for char in word:\n",
        "        if char.isalnum():\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "jkjnXksYHYZN"
      },
      "outputs": [],
      "source": [
        "class NER_Preprocessor:\n",
        "    def __init__(self, trainset, testset, valset=None):\n",
        "        self.trainset = trainset\n",
        "        self.testset = testset\n",
        "        self.valset = valset\n",
        "        if valset is None:\n",
        "            self.split_val()\n",
        "\n",
        "    def split_val(self, split_train_false=False):\n",
        "        if split_train_false:\n",
        "            self.trainset = self.trainset + self.valset\n",
        "        self.trainset, self.valset = train_test_split(\n",
        "            self.trainset, test_size=0.15, random_state=42)\n",
        "\n",
        "    def init_tags(self, dataset):\n",
        "        labeled_output = []\n",
        "        for entry in dataset:\n",
        "            tag_entry = {}\n",
        "            tag_entry[\"id\"] = entry[\"id\"]\n",
        "            annotations = entry[\"annotations\"][0]\n",
        "            sentence = entry[\"data\"][\"text\"].replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
        "            sentence = sentence\n",
        "            tag_entry[\"text\"] = \"\"\n",
        "            tag_entry[\"labels\"] = []\n",
        "            no_tags = False\n",
        "            if (len(annotations[\"result\"]) == 0):\n",
        "                no_tags = True\n",
        "                continue\n",
        "            \n",
        "            word_ranges = find_word_indices(sentence)\n",
        "            for i in range(len(word_ranges)):\n",
        "                found = False\n",
        "                for resultObj in annotations[\"result\"]:\n",
        "                    if (word_ranges[i][0] >= resultObj[\"value\"][\"start\"] and word_ranges[i][1] <= resultObj[\"value\"][\"end\"]):\n",
        "                        tag_entry[\"text\"] += sentence[word_ranges[i][0]:word_ranges[i][1]+1] + \" \"\n",
        "                        tag_entry[\"labels\"].append(\"I_\" + resultObj[\"value\"][\"labels\"][0])\n",
        "                        found = True\n",
        "                        break\n",
        "                    \n",
        "                if not found:\n",
        "                    tag_entry[\"text\"] += sentence[word_ranges[i][0]:word_ranges[i][1]+1] + \" \"\n",
        "                    tag_entry[\"labels\"].append(\"O\")\n",
        "                \n",
        "            for i in range(len(tag_entry[\"labels\"])):\n",
        "                if i==0 and tag_entry[\"labels\"][i] != \"O\":\n",
        "                    tag_entry[\"labels\"][i] = \"B_\" + tag_entry[\"labels\"][i][2:]\n",
        "                elif tag_entry[\"labels\"][i] != \"O\" and tag_entry[\"labels\"][i-1] == \"O\":\n",
        "                    tag_entry[\"labels\"][i] = \"B_\" + tag_entry[\"labels\"][i][2:]\n",
        "             \n",
        "            labeled_output.append(tag_entry)\n",
        "            \n",
        "        for entry in range(len(labeled_output)):\n",
        "            s = \"\"\n",
        "            for wordnum in range(len(labeled_output[entry][\"text\"].split())):\n",
        "                if not check_alphanumeric_in_word(labeled_output[entry][\"text\"].split()[wordnum]):\n",
        "                    newword = labeled_output[entry][\"text\"].split()[wordnum]\n",
        "                else:\n",
        "                    newword = re.sub(r'[^\\w\\s]','',labeled_output[entry][\"text\"].split()[wordnum])\n",
        "                s += newword + \" \"\n",
        "            labeled_output[entry][\"text\"] = s\n",
        "                \n",
        "            \n",
        "            \n",
        "            \n",
        "        return labeled_output\n",
        "\n",
        "    def initialize(self):\n",
        "        self.labeled_trainset = self.init_tags(self.trainset)\n",
        "        self.labeled_valset = self.init_tags(self.valset)\n",
        "        self.labeled_testset = self.init_tags(self.testset)\n",
        "\n",
        "    def get_tagged(self):\n",
        "        return (self.labeled_trainset, self.labeled_valset, self.labeled_testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "NER_preprocessor = NER_Preprocessor(NER_train_json, NER_test_json)\n",
        "NER_preprocessor.initialize()\n",
        "NER_train,NER_val,NER_test = NER_preprocessor.get_tagged()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (not os.path.exists(\"./data_processed\")):\n",
        "    os.makedirs(\"./data_processed\")\n",
        "\n",
        "with open(\"./data_processed/NER_train_tagged.json\", \"w\") as file:\n",
        "    json.dump(NER_train, file)\n",
        "    \n",
        "with open(\"./data_processed/NER_val_tagged.json\", \"w\") as file:\n",
        "    json.dump(NER_val, file)\n",
        "\n",
        "with open(\"./data_processed/NER_test_tagged.json\", \"w\") as file:\n",
        "    json.dump(NER_test, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "LR_Preprocessor = LR_Preprocessor(LR_train_json,LR_test_json,LR_val_json)\n",
        "LR_Preprocessor.initizalize()\n",
        "LR_train,LR_val,LR_test = LR_Preprocessor.get_tagged_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./data_processed/LR_train_tagged.json\", \"w\") as file:\n",
        "    json.dump(LR_train, file)\n",
        "\n",
        "with open(\"./data_processed/LR_val_tagged.json\", \"w\") as file:\n",
        "    json.dump(LR_val, file)\n",
        "    \n",
        "with open(\"./data_processed/LR_test_tagged.json\", \"w\") as file:\n",
        "    json.dump(LR_test, file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
