{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import gensim\n",
    "import re\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../processed/LR_train_tagged.json') as f: \n",
    "    LR_train = json.load(f)\n",
    "    \n",
    "with open('../processed/LR_test_tagged.json') as f:\n",
    "    LR_test = json.load(f)\n",
    "    \n",
    "with open('../processed/LR_val_tagged.json') as f:\n",
    "    LR_val = json.load(f)\n",
    "\n",
    "with open('../processed/NER_train_tagged.json') as f:\n",
    "    NER_train = json.load(f)\n",
    "\n",
    "with open('../processed/NER_test_tagged.json') as f:\n",
    "    NER_test = json.load(f)\n",
    "\n",
    "with open('../processed/NER_val_tagged.json') as f:\n",
    "    NER_val = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = KeyedVectors.load_word2vec_format('../.vector_cache/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# glovemodel = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B_PRECEDENT': 0, 'I_PROVISION': 1, 'B_PROVISION': 2, 'B_ORG': 3, 'I_STATUTE': 4, 'B_DATE': 5, 'I_WITNESS': 6, 'I_DATE': 7, 'B_STATUTE': 8, 'I_PRECEDENT': 9, 'I_PETITIONER': 10, 'B_RESPONDENT': 11, 'I_ORG': 12, 'B_CASE_NUMBER': 13, 'I_OTHER_PERSON': 14, 'B_GPE': 15, 'B_COURT': 16, 'O': 17, 'B_WITNESS': 18, 'I_COURT': 19, 'I_CASE_NUMBER': 20, 'I_GPE': 21, 'I_JUDGE': 22, 'I_RESPONDENT': 23, 'B_JUDGE': 24, 'B_PETITIONER': 25, 'B_OTHER_PERSON': 26, 'PAD': 27}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = []\n",
    "for entry in NER_train:\n",
    "    labels = entry['labels']\n",
    "    for label in labels:\n",
    "        unique_labels.append(label)\n",
    "\n",
    "label_dict = {}\n",
    "unique_labels = list(set(unique_labels))\n",
    "\n",
    "for label_index in range(len(unique_labels)):\n",
    "    label_dict[unique_labels[label_index]] = label_index\n",
    "\n",
    "label_dict['PAD'] = len(unique_labels)\n",
    "# label_dict['UNK'] = len(unique_labels) + 1\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "dc09913bba844e3c8d920c9df2970988\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "id = 0\n",
    "for entry in NER_train:\n",
    "    if (maxlen < len(entry['text'].split())):\n",
    "        maxlen = len(entry['text'].split())\n",
    "        id = entry['id']\n",
    "print(maxlen)\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_dataset(Dataset):\n",
    "    def __init__(self, dataset, embedding=\"word2vec\"):\n",
    "        self.padding_word = \"PAD\"\n",
    "        if embedding == \"word2vec\":\n",
    "            self.model = w2vmodel\n",
    "        # elif embedding == \"glove\":\n",
    "        #     self.model = glovemodel\n",
    "        self.data = dataset\n",
    "        self.input = []\n",
    "        self.labels = []\n",
    "        for entry in dataset:\n",
    "            padded_entry = entry[\"text\"].split() + [self.padding_word] * (75- len(entry[\"text\"].split()))\n",
    "            self.input.append(padded_entry)\n",
    "            padded_labels = entry[\"labels\"] + [self.padding_word] * (75 - len(entry[\"labels\"]))\n",
    "            self.labels.append(padded_labels)\n",
    "\n",
    "            # self.input.append(entry[\"text\"].split())\n",
    "            # self.labels.append(entry[\"labels\"])\n",
    "\n",
    "        self.tag_to_index = label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.input[idx]\n",
    "        word_vecs = []\n",
    "        labels = []\n",
    "        for word_index in range(len(sentence)):\n",
    "            if sentence[word_index] not in self.model:\n",
    "                # if self.labels[idx][word_index] != \"O\":\n",
    "                #     print(sentence[word_index])\n",
    "                word_vecs.append(np.zeros(300))\n",
    "                labels.append(self.tag_to_index[\"O\"])\n",
    "                continue\n",
    "            else:\n",
    "                word_vecs.append(self.model[sentence[word_index]])\n",
    "                labels.append(self.tag_to_index[self.labels[idx][word_index]])\n",
    "\n",
    "        return torch.tensor(word_vecs), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_train_loader = DataLoader(NER_dataset(NER_train, \"word2vec\"), batch_size=64, shuffle=True)\n",
    "NER_val_loader = DataLoader(NER_dataset(NER_val, \"word2vec\"), batch_size=64, shuffle=True)\n",
    "NER_test_loader = DataLoader(NER_dataset(NER_test, \"word2vec\"), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_f1_scores = []\n",
    "    val_f1_scores = []\n",
    "    train_accuracy_scores = []\n",
    "    val_accuracy_scores = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        all_train_labels = []\n",
    "        all_train_preds = []\n",
    "        all_val_labels = []\n",
    "        all_val_preds = []\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
    "            outputs, hn = model(inputs)\n",
    "            # print(\"old shape: \", outputs.shape)\n",
    "            outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "            # print(\"new shape: \", outputs.shape)\n",
    "            labels = labels.reshape(-1)\n",
    "            # print(\"labels shape: \", labels.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "        train_f1 = f1_score(all_train_labels, all_train_preds, average='macro')\n",
    "        train_accuracy_scores.append(train_accuracy)\n",
    "        train_f1_scores.append(train_f1)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
    "                outputs, hn = model(inputs)\n",
    "                outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "                labels = labels.reshape(-1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "            val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "            val_f1 = f1_score(all_val_labels, all_val_preds, average='macro')\n",
    "            val_accuracy_scores.append(val_accuracy)\n",
    "            val_f1_scores.append(val_f1)\n",
    "\n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(val_loader))\n",
    "        print(f\"Epoch {epoch + 1}\\n\"\n",
    "              f\"Train loss: {train_losses[-1]}, Val loss: {val_losses[-1]}\\n\"\n",
    "              f\"Train accuracy: {train_accuracy}, Val accuracy: {val_accuracy}\\n\"\n",
    "              f\"Train F1: {train_f1}, Val F1: {val_f1}\")\n",
    "        print(\"=====================================================================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(300, 128, batch_first=True)\n",
    "        self.linear = nn.Linear(128, len(label_dict))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, hn = self.rnn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        return x, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.RNN(300, len(label_dict), 2, batch_first=True)\n",
    "model = torch.nn.LSTM(300, len(label_dict), 1, batch_first=True)\n",
    "# model = torch.nn.GRU(300, len(label_dict), 1, batch_first=True)\n",
    "# model = RNNModel()\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train loss: 1.774511386477758, Val loss: 1.6592756924421892\n",
      "Train accuracy: 0.9235748430810159, Val accuracy: 0.949322033898305\n",
      "Train F1: 0.0693409157237286, Val F1: 0.06990946199517091\n",
      "=====================================================================================================\n",
      "Epoch 2\n",
      "Train loss: 1.65402147599629, Val loss: 1.653259945952374\n",
      "Train accuracy: 0.95132393897826, Val accuracy: 0.9496516007532957\n",
      "Train F1: 0.06955307304424747, Val F1: 0.06943986353676837\n",
      "=====================================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[203], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNER_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNER_val_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[201], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     16\u001b[0m all_val_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     20\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32), labels\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     21\u001b[0m     outputs, hn \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[1;32mc:\\Users\\Jaskaran\\miniconda3\\envs\\mlenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Jaskaran\\miniconda3\\envs\\mlenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Jaskaran\\miniconda3\\envs\\mlenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Jaskaran\\miniconda3\\envs\\mlenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[199], line 40\u001b[0m, in \u001b[0;36mNER_dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     37\u001b[0m         word_vecs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[sentence[word_index]])\n\u001b[0;32m     38\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtag_to_index[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx][word_index]])\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_vecs\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(labels)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, NER_train_loader, NER_val_loader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9632465277777778 Test F1: 0.2976833335124903\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_test_labels = []\n",
    "all_test_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in NER_test_loader:\n",
    "        inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
    "        outputs, hn = model(inputs)\n",
    "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "        labels = labels.reshape(-1)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(all_test_labels, all_test_preds)\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average='macro')\n",
    "print(f\"Test accuracy: {test_accuracy} Test F1: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The injuries of Shish Pal (D-3) are as follows: (i) Incised Wounds at (Lt) pareital area of skull at top size 12 cm x 1-1/2 cms x Brain matter deep obliquely & Tailing Backwards. (ii) Multiple Incised Wounds at (Lt) Head Laterally & at Back side. ', 'The learned Counsel for the parties informed that the matter is still not decided by the larger Bench of the Supreme Court. ', 'therefore, she was not entitled to any damages. ', 'Some of those 15 also had injuries on their persons which appeared to be due to lathi charge at village Khabra. ', 'I am unable to subscribe to the Second reasoning given by Piggott J. in AIR 1916 All 51 that if an appeal against a decree can lie in certain circumstances the decree may be regarded as one open to appeal for purposes of Order 43 Rule 1(d). ', 'According to Sri Haranahalli, the complaint as against respondent/accused No. 2 was definitely maintainable and could be proceeded with against him in view of no bar thereto under section 446 of the Companies Act. ', \"Pradeep Kumar Verma v. State of Bihar & Anr., AIR 2007 SC 3059, and came to the conclusion that in the event that the accused's promise is not false and has not been made with the sole intention to seduce the prosecutrix to indulge in sexual acts, such an act(s) would not JUDGEMENT 8 | P a g e State Vs. Dildar amount to rape. \", 'In St. Xaviers College case (AIR 1974 SC 1389) (supra), the validity of S. 51A of Gujarat University Act came to be considered by a Constitutional Bench consisting of 9 judges. ', 'As has already been discussed above, the accused were not identified initially 19.5.2003 when the incident had occurred inasmuch as a search for the accused was made at various places by Harpreet Singh Inspector/SHO (PW17) and by ASI Kanwaljit Singh (PW14). ', 'One month thereafter, the accused and his family vacated the adjacent portion. ', \"One or two subordinate staff was also included in the team and all the members of the team, so constituted by PW\\xad8 K.K. Sood, alongwith PW\\xad4 R. Roy, himself, reached Hotel 'My Inn' at 901, Chandiwali Lane, Paharganj, New Delhi. \", 'In the instant case, since the property was pledged to the respondent bank and for non-payment of the loan amount the property was attached for the purposes of sale, provisions of the Act, 2002 will be applicable in the instant case which bars such suits and grant of injunction. ', 'According to the petitioner, not deciding the objection has vitiated the order dated 16 th May, 2014. ', 'In view of aforesaid appreciation of evidence on record, I hold accused guilty for committing offence punishable U/s. 138 NI Act. Announced in open Court (PRASHANT SHARMA) on 22nd August 2014 ARC/ACJ/CCJ: New Delhi Patiala House Courts/22.08.2014 ', 'Mr. Mohnish Bhalla, PW-4, in his deposition at Exh.81, who was Intelligence Officer on Deputation with NCB, has clearly stated that at about 7:30, they reached the house of accused No. 1-Iqbal Moosa, who was present there in the veranda and he is said to have stated his name to be Iqbal Moosa Patel. ', 'PW.9 Digamber who was a witness of inquest turned hostile, but in his cross-examination he stated that he went to the house of accused Maroti at about 9.00 a.m. and had seen the body of the deceased with a piece of cloth tied around her mouth. ', \"The matter was thereafter placed before a Division Bench of Hon'ble the Supreme Court for decision in the light of judgment of the Constitution Bench. \", 'A preliminary examination is essentially a screening test for short-listing candidates to a reasonable and practical extent so that in the main examination, the confusion and disorder likely to be created because of large number of candidates appearing is avoided. ', 'The Tribunal doubted the presence of PWs 1, 3 and 4 and rejected their evidence. ', 'Thus it is not in dispute that FIR had been registered against Yogesh and criminal trial was also pending against him in the concerned court. ', 'On 22.12.2012, the appellant facing the aforementioned trial as accused made a statement under section 294 Cr.P.C read with section 313/281 Cr.P.C admitting the genuineness of certain documents relied upon by the prosecution which include the FIR, the mechanical inspection report of the scooter and the mechanical inspection report of the bus which were thereupon entered in evidence as documents Ex. ', 'The question is well settled in view of the decision of a seven-Judge Bench of this Court in Synthetics and Chemicals Ltd. v. State of U.P....... 25. ', 'But these considerations have no bearing on the crucial factors which invoke the application of the definition in the Act as already set out elaborately by us. ', 'They were requested to examine the rolls as finally published on December 31, 1981. ', 'Witness Bhikhubhai in his deposition Exh. 17 did not support the prosecution and was cross-examined by the public prosecutor. ', 'This argument is noted to be rejected only, because if RPSC has for the reason best known to it, taken erroneous decision, that would not bind this court. ', 'No cogent reasons have been disclosed as to why these witnesses who are sought to be examined now could not be examined earlier. ', 'It has been claimed by PW2 Sh. G.L. Khandelwal that property furnished as collateral was found to be fake and such fact has not been challenged by accused Bhajan Singh. ', 'The fee was to be levied only in respect of the tobacco imported into the State The State of Travancore- Cochin collected licence fee from the appellants for the period from August 17, 1950 to December 31, 1957. ', 'P.Ws. 1 and 12 have been disbelieved by the trial court. ', 'Varadachariar J., as he then was, pointed out \"that Section 37 of the Indian Contract Act which lays down that \\'parties to a contract must either perform or offer to perform their respective promises\\' \" qualifies this statement by the words \"unless such performance is dispensed with or excused under the provisions of any other law.\" ', 'The report further notes that most of the members of the SAC were not the residents of the locality (Shella Village) and were living in Shillong while occasionally visiting Shella. ', 'Again the rent for the period January to March, 2011 was sent through money order on dated 14.03.2011 which was also received back on 17.03.2011. ', 'I attest to the accuracy and authenticity of this document ITA No. 591 of 2009 & connected appeals. ', \"She has further placed reliance on the decision of the Hon'ble Apex Court in Rajinder Prasad v. Bashir and Others, reported in AIR 2001 SC 3524, wherein the Hon'ble Apex Court \", 'Another reason mentioned by the court below is that \"For Plot ACBD the eastern boundary without any doubt is Kodappadi thodu and Kodappadimala and the Western boundary is Muthalarappan mala. ', 'On 16-4-1984 the claimant amended the claim petition and claimed Rs. 35,00,000/-. ', 'That Article 14 gets attracted in a case of disproportionate punishment was the view of this Court in Bhagat Ram v. State of H.P., also. ', 'The advertisement dated 25th May, 2011 is for the post of Lab Technician under Rajasthan Medical & Health Subordinate Service Rules, 1965 (for short the Rules of 1965). ', 'No plea was taken by Satnam Singh, Kulwinder Singh, Jagdev Singh and Amrik Singh, that they were only the labourers, engaged by the owner, or the driver of the truck, to load the gunny bags, containing poppy-husk, and unload the same, at a particular destination. ', 'The correctness of the aforesaid decision, particularly in regard to the conclusion that the High Court at Allahabad was competent to hear cases arising in Oudh area, was doubted by one of the Judges sitting in the Full Bench in Umashanker v. The State (AIR 1971 All 96). ', '(10) Mr. Dhanda contended with force that it is the provisions of the Sale of Goods Act which determine the legal requirements for transfer of a motor vehicle and that section 54 of the Transfer of Property Act, dose not have any application to the facts of the case. ', 'The assessee is a registered firm which carries on business as a dealer in radio and radio accessories. ', 'The prosecution to prove its case brought into the witness box, Dr. Krishan Gopal PW1, Amar Singh PW2, Gurdev Singh PW3, Mukhtiar Singh PW4, Karnail Singh PW5, Jangir Singh PW6, Sukhdev Singh PW7, Surjit Kaur PW8, Bikkar Singh PW9, Harcharanjit Singh PW10, Chamkaur Singh PW11, HC Ajaib Singh PW12, ASI Darshan Singh PW13, SI Sarabjit Rai PW14, C. Davinder Pal Singh PW15 and Sukhvinder Pal Singh PW16. ', '8. Shri. Shabbir Mohd. Ali @ Firoz Khan Gaffar Khan Nanku M/30yrs & ', 'On the other hand plaintiff has placed on record, a copy of case FIR No. 85/11 U/s. 406/420/434 IPC lodged against defendants on complaint by plaintiff that defendants induced the plaintiff and one Sh. Sunil Pawar to pay Rs.10 Lacs each to procure the tender for supply of cement. ', 'This sounds probable in the circumstances wherein right hand of the accused No.1 Amjad was fractured and made defunct in the assault leaving no option but to use his left hand. ', 'In this case it has been held that the essence of the Code of Civil Procedure is to be exhaustive, so far as it goes. ', 'Learned counsel further relied on the judgement of Supreme Court in Narsinbhai Haribhai Prajapati vs. Chhatrasinh & Ors.-AIR 1977 SC 1753 to argue that recovery of blood stained weapons would not be sufficient to convict the accused. ', 'On this reasoning also we hold that the order of the CIT (Appeals) is correct. ', 'That means that the municipality had no power to levy anything in excess of 10 pies per Boja.\" ', 'There are Benches of these Tribunals in the State of Madhya Pradesh but their main seats are outside the State of Madhya Pradesh. ', 'Appeals from the judgments and orders dated August 7, 1956, of the Allahabad High Court in Special Appeals Nos. 151 and 152 of 1955. ', 'In Tata Iron and Steel Co. Ltd v. Venkata Swamy and Ors. 1976 LIC 1313 it has been held that the gardert-Mazdoor and Malis working in the gardens attached to the bungalows occupied by any officer of a Mining industry cannot be said to be persons employed in a mine. ', 'The documentary evidence consists mostly of letters written by Purabi to Basudeb, as also letters to and fro between Pulak Banerjee on one hand and Basudeb and his people on the other. ', 'Therefore, a clear distinction is made by the learned Chief Justice in this case between agreements entered into by the collector as a subordinate to the Commissioner and the Collector as the agent Of the Secretary of State. ', 'A. K. Sen, Dinesh Vyas, Manulal, P. H. Parekh, C. B. Singh, M. Mudgal, and N. Mundal for the Respondent No. 1 ', 'On the above discussions, we hold that the District Collector is the only competent authority to exercise the power under Section 4 (1) of the Act for issue of notification, and such power cannot be delegated to any other officer including the Additional Collector in whose name the notification has been issued. ', 'The law on the question of consideration of charge is well settled. ', 'Later, a stomach pump was forcibly used to extract from his stomach what were found to be narcotic pills. ', 'As per the receipt, on which the reliance is placed by the plaintiff, Rs. 25 Lacs were paid by the plaintiff to defendant No. 1- Govindbhai Bhagvanbhai Sakhia, however, said receipt is seriously disputed. ', \"My father therefore, could not come to Hyderabad to file Rx.B157A and 157B and therefore had given me this paper to file in this Ilon'ble Court. \", 'It is not in dispute that, until at any rate 1956, appellant Raghunath and the other members of the family formed a joint and undivided Hindu family of which Raghunath, on the death of his father Laxman in June 1954, became the karta and the manager. ', 'Though the petitioner has disputed that he has not executed the guarantee deed dated 17.8.1988 for Rs.56.80 lakhs, however, a copy of the said guarantee deed placed on record discloses that the petitioner did execute the deed. ')\n",
      "tensor([[17, 17, 17,  ..., 17, 17, 17],\n",
      "        [17, 17, 17,  ..., 17, 17, 17],\n",
      "        [17, 17, 17,  ..., 17, 17, 17],\n",
      "        ...,\n",
      "        [17, 17, 17,  ..., 17, 17, 17],\n",
      "        [17, 17, 17,  ..., 17, 17, 17],\n",
      "        [17, 17, 17,  ..., 17, 17, 17]])\n",
      "tensor([[16, 24, 24,  ..., 20, 20, 20],\n",
      "        [16, 20, 25,  ..., 20, 20, 20],\n",
      "        [24, 20, 20,  ..., 20, 20, 20],\n",
      "        ...,\n",
      "        [15,  6,  6,  ..., 20, 20, 20],\n",
      "        [20, 20, 20,  ..., 20, 20, 20],\n",
      "        [16, 20, 14,  ..., 20, 20, 20]])\n",
      "torch.Size([64, 75, 27])\n"
     ]
    }
   ],
   "source": [
    "for input, label, sentence in NER_train_loader:\n",
    "    print(sentence)\n",
    "    outputs, hn = model(input.to(device).to(torch.float32))\n",
    "    # print label and prediction\n",
    "    _, predicted = torch.max(outputs, 2)\n",
    "    print(label)\n",
    "    print(predicted)\n",
    "\n",
    "    print(outputs.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
