{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import gensim\n",
    "import re\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.models import KeyedVectors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../processed/LR_train_tagged.json') as f: \n",
    "    LR_train = json.load(f)\n",
    "    \n",
    "with open('../processed/LR_test_tagged.json') as f:\n",
    "    LR_test = json.load(f)\n",
    "    \n",
    "with open('../processed/LR_val_tagged.json') as f:\n",
    "    LR_val = json.load(f)\n",
    "\n",
    "with open('../processed/NER_train_tagged.json') as f:\n",
    "    NER_train = json.load(f)\n",
    "\n",
    "with open('../processed/NER_test_tagged.json') as f:\n",
    "    NER_test = json.load(f)\n",
    "\n",
    "with open('../processed/NER_val_tagged.json') as f:\n",
    "    NER_val = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = KeyedVectors.load_word2vec_format('../.vector_cache/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "glovemodel = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B_PRECEDENT': 0, 'I_PROVISION': 1, 'B_PROVISION': 2, 'B_ORG': 3, 'I_STATUTE': 4, 'B_DATE': 5, 'I_WITNESS': 6, 'I_DATE': 7, 'B_STATUTE': 8, 'I_PRECEDENT': 9, 'I_PETITIONER': 10, 'B_RESPONDENT': 11, 'I_ORG': 12, 'B_CASE_NUMBER': 13, 'I_OTHER_PERSON': 14, 'B_GPE': 15, 'B_COURT': 16, 'O': 17, 'B_WITNESS': 18, 'I_COURT': 19, 'I_CASE_NUMBER': 20, 'I_GPE': 21, 'I_JUDGE': 22, 'I_RESPONDENT': 23, 'B_JUDGE': 24, 'B_PETITIONER': 25, 'B_OTHER_PERSON': 26}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = []\n",
    "for entry in NER_train:\n",
    "    labels = entry['labels']\n",
    "    for label in labels:\n",
    "        unique_labels.append(label)\n",
    "\n",
    "label_dict = {}\n",
    "unique_labels = list(set(unique_labels))\n",
    "\n",
    "for label_index in range(len(unique_labels)):\n",
    "    label_dict[unique_labels[label_index]] = label_index\n",
    "    \n",
    "# print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "dc09913bba844e3c8d920c9df2970988\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "id = 0\n",
    "for entry in NER_train:\n",
    "    if (maxlen < len(entry['text'].split())):\n",
    "        maxlen = len(entry['text'].split())\n",
    "        id = entry['id']\n",
    "print(maxlen)\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_dataset(Dataset):\n",
    "    def __init__(self, dataset, embedding=\"word2vec\"):\n",
    "        self.padding_word = \"PAD\"\n",
    "        if embedding == \"word2vec\":\n",
    "            self.model = w2vmodel\n",
    "        elif embedding == \"glove\":\n",
    "            self.model = glovemodel\n",
    "        self.data = dataset\n",
    "        self.input = []\n",
    "        self.labels = []\n",
    "        for entry in dataset:\n",
    "            padded_entry = entry[\"text\"].split() + [self.padding_word] * (75- len(entry[\"text\"].split()))\n",
    "            self.input.append(padded_entry)\n",
    "            padded_labels = entry[\"labels\"] + [\"O\"] * (75 - len(entry[\"labels\"]))\n",
    "            self.labels.append(padded_labels)\n",
    "\n",
    "        self.tag_to_index = label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.input[idx]\n",
    "        word_vecs = []\n",
    "        labels = []\n",
    "        for word_index in range(len(sentence)):\n",
    "            if sentence[word_index] not in self.model:\n",
    "                word_vecs.append(np.zeros(300))\n",
    "                labels.append(self.tag_to_index[\"O\"])\n",
    "            else:\n",
    "                word_vecs.append(self.model[sentence[word_index]])\n",
    "                labels.append(self.tag_to_index[self.labels[idx][word_index]])\n",
    "\n",
    "        return torch.tensor(word_vecs), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_train_loader = DataLoader(NER_dataset(NER_train, \"word2vec\"), batch_size=64, shuffle=True)\n",
    "NER_val_loader = DataLoader(NER_dataset(NER_val, \"word2vec\"), batch_size=64, shuffle=True)\n",
    "NER_test_loader = DataLoader(NER_dataset(NER_test, \"word2vec\"), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_f1_scores = []\n",
    "    val_f1_scores = []\n",
    "    train_accuracy_scores = []\n",
    "    val_accuracy_scores = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        all_train_labels = []\n",
    "        all_train_preds = []\n",
    "        all_val_labels = []\n",
    "        all_val_preds = []\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
    "            outputs, hn = model(inputs)\n",
    "            outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "            labels = labels.reshape(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "        train_f1 = f1_score(all_train_labels, all_train_preds, average='macro')\n",
    "        train_accuracy_scores.append(train_accuracy)\n",
    "        train_f1_scores.append(train_f1)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
    "                outputs, hn = model(inputs)\n",
    "                outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "                labels = labels.reshape(-1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "            val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "            val_f1 = f1_score(all_val_labels, all_val_preds, average='macro')\n",
    "            val_accuracy_scores.append(val_accuracy)\n",
    "            val_f1_scores.append(val_f1)\n",
    "\n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(val_loader))\n",
    "        print(f\"Epoch {epoch + 1}\\n\"\n",
    "              f\"Train loss: {train_losses[-1]} Val loss: {val_losses[-1]}\\n\"\n",
    "              f\"Train accuracy: {train_accuracy} Val accuracy: {val_accuracy}\\n\"\n",
    "              f\"Train F1: {train_f1} Val F1: {val_f1}\")\n",
    "        print(\"=====================================================================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.nn.RNN(300, 27, 1, batch_first=True)\n",
    "model = torch.nn.LSTM(300, 27, 1, batch_first=True, bidirectional=True)\n",
    "# model = torch.nn.GRU(300, 27, 1, batch_first=True, bidirectional=True)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train loss: 3.728897319899665 Val loss: 3.6773921925088633\n",
      "Train accuracy: 0.4803125909298749 Val accuracy: 0.5821280602636535\n",
      "Train F1: 0.013192550859904392 Val F1: 0.016300926947764298\n",
      "=====================================================================================================\n",
      "Epoch 2\n",
      "Train loss: 3.643454010524447 Val loss: 3.6110207930855127\n",
      "Train accuracy: 0.6081689321195494 Val accuracy: 0.6437099811676082\n",
      "Train F1: 0.015126597213781916 Val F1: 0.01697252987537214\n",
      "=====================================================================================================\n",
      "Epoch 3\n",
      "Train loss: 3.5818128756114413 Val loss: 3.552329954893693\n",
      "Train accuracy: 0.6771002203100969 Val accuracy: 0.7168926553672317\n",
      "Train F1: 0.016131097270643425 Val F1: 0.018641612772841133\n",
      "=====================================================================================================\n",
      "Epoch 4\n",
      "Train loss: 3.530968427658081 Val loss: 3.5069762209187383\n",
      "Train accuracy: 0.7579099638358897 Val accuracy: 0.7981826741996233\n",
      "Train F1: 0.017033437198460795 Val F1: 0.01965104014940729\n",
      "=====================================================================================================\n",
      "Epoch 5\n",
      "Train loss: 3.48833039450267 Val loss: 3.4665198222450586\n",
      "Train accuracy: 0.829320364135179 Val accuracy: 0.8561016949152542\n",
      "Train F1: 0.018020016625602566 Val F1: 0.020512165403590365\n",
      "=====================================================================================================\n",
      "Epoch 6\n",
      "Train loss: 3.4525413626716253 Val loss: 3.435242694357167\n",
      "Train accuracy: 0.8759496196533234 Val accuracy: 0.8918738229755179\n",
      "Train F1: 0.018511465844381018 Val F1: 0.02093321349201232\n",
      "=====================================================================================================\n",
      "Epoch 7\n",
      "Train loss: 3.4223875621008495 Val loss: 3.4108659391817837\n",
      "Train accuracy: 0.9045450388660266 Val accuracy: 0.9134934086629002\n",
      "Train F1: 0.019142388503260874 Val F1: 0.02126687955583193\n",
      "=====================================================================================================\n",
      "Epoch 8\n",
      "Train loss: 3.3964602020051746 Val loss: 3.38092129126839\n",
      "Train accuracy: 0.9209294592010642 Val accuracy: 0.9259416195856874\n",
      "Train F1: 0.019600420517229183 Val F1: 0.0213334487974598\n",
      "=====================================================================================================\n",
      "Epoch 9\n",
      "Train loss: 3.373614161733597 Val loss: 3.3610457648401675\n",
      "Train accuracy: 0.9313530365382218 Val accuracy: 0.9346516007532957\n",
      "Train F1: 0.019690533868593863 Val F1: 0.022113389700939047\n",
      "=====================================================================================================\n",
      "Epoch 10\n",
      "Train loss: 3.353147650521899 Val loss: 3.3425358482029126\n",
      "Train accuracy: 0.9386490418589184 Val accuracy: 0.9408286252354049\n",
      "Train F1: 0.02060275003215775 Val F1: 0.02248719395239827\n",
      "=====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(model, NER_train_loader, NER_val_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9339936775553214 Test F1: 0.023070996491301135\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_test_labels = []\n",
    "all_test_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in NER_test_loader:\n",
    "        inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
    "        outputs, hn = model(inputs)\n",
    "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "        labels = labels.reshape(-1)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(all_test_labels, all_test_preds)\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average='macro')\n",
    "print(f\"Test accuracy: {test_accuracy} Test F1: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
